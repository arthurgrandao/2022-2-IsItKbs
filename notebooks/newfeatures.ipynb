{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import vstack, hstack, csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_counter(string, type=None):\n",
    "    if (type == 'c'):\n",
    "        return {letter: str(string).count(letter) for letter in 'bcdfghjklmnpqrstvwxyz'}\n",
    "    elif (type == 'v'):\n",
    "        return {letter: str(string).count(letter) for letter in 'aeiou'}  \n",
    "    return {letter: str(string).count(letter) for letter in 'abcdefghijklmnopqrstuvwxyz'}\n",
    "\n",
    "def type_counter(string, type):    \n",
    "    return sum(letter_counter(string, type).values())\n",
    "\n",
    "def type_ratio(string, type):\n",
    "    if (len(string) == 0):\n",
    "        return 0\n",
    "    return type_counter(string, type)/len(string)\n",
    "\n",
    "def repetitions_character(repetitions, caractere):\n",
    "        x = repetitions.get(caractere)\n",
    "        return x if x != None else 0\n",
    "\n",
    "def ttr(string):\n",
    "    if (len(string) == 0):\n",
    "        return 0\n",
    "    ttr = len(set(string)) / len(string)\n",
    "    return ttr\n",
    "    \n",
    "def repetitions(string):\n",
    "    try:\n",
    "        resultados = []\n",
    "        size = len(string)\n",
    "        valor = 1\n",
    "\n",
    "        for l in range(0, size):\n",
    "            if l <= size-2 and string[l] == string[l+1]:\n",
    "                valor += 1\n",
    "            else:\n",
    "                resultados.append(tuple((string[l], valor)))\n",
    "                valor = 1\n",
    "        return dict(sorted(resultados))\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def repetitions_type(string, type):\n",
    "    if type == 'c':\n",
    "        letters = 'bcdfghjklmnpqrstvwxyz'\n",
    "    else:\n",
    "        letters = 'aeiou'\n",
    "    \n",
    "    resultados = []\n",
    "    size = len(string)\n",
    "    valor = 0\n",
    "\n",
    "    for l in string:\n",
    "        if l in letters:\n",
    "            valor += 1\n",
    "        else:\n",
    "            resultados.append(valor)\n",
    "            valor = 0\n",
    "    resultados.append(valor)\n",
    "    \n",
    "    return max(resultados)\n",
    "\n",
    "def bigram_counter(lista):\n",
    "  dic = {}\n",
    "  for i in lista:\n",
    "    if i in dic:\n",
    "      dic[i] +=1\n",
    "    else:\n",
    "      dic[i] =1\n",
    "  return dic\n",
    "\n",
    "def bigrams(string):\n",
    "    bigrams = []\n",
    "    for i in range(len(string)-1):\n",
    "        bigrams.append(string[i]+string[i+1])\n",
    "\n",
    "    return bigram_counter(bigrams)\n",
    "\n",
    "def bigram_max_occurance(string):\n",
    "    try:\n",
    "        return (sorted(bigrams(string).values(), reverse=True))[0]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"..\\\\data\\\\interim\\\\naturals.csv\", \"r\", encoding=\"utf-8\") as file0:\n",
    "    X0 = pd.DataFrame(pd.read_csv(file0, keep_default_na=False))\n",
    "\n",
    "with open (\"..\\\\data\\\\interim\\\\mashings.csv\", \"r\", encoding=\"utf-8\") as file1:\n",
    "    X1 = pd.DataFrame(pd.read_csv(file1, keep_default_na=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resembles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>having</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11648</th>\n",
       "      <td>It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>bloom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11650</th>\n",
       "      <td>weights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11651</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11652</th>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11653 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      resembles\n",
       "1        attacks\n",
       "2          under\n",
       "3         having\n",
       "4          point\n",
       "...          ...\n",
       "11648         It\n",
       "11649      bloom\n",
       "11650    weights\n",
       "11651         in\n",
       "11652        use\n",
       "\n",
       "[11653 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#O dataframe naturals é embaralhado e reduzido para o tamanho do de mashings\n",
    "X0 = shuffle(X0, random_state=777).reset_index(drop=True)\n",
    "X0 = X0[:len(X1)]\n",
    "X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  mash\n",
      "0      resembles     0\n",
      "1        attacks     0\n",
      "2          under     0\n",
      "3         having     0\n",
      "4          point     0\n",
      "...          ...   ...\n",
      "11648         It     0\n",
      "11649      bloom     0\n",
      "11650    weights     0\n",
      "11651         in     0\n",
      "11652        use     0\n",
      "\n",
      "[11653 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Add da coluna binária 'mash'\n",
    "X0[\"mash\"] = 0\n",
    "X1[\"mash\"] = 1\n",
    "print(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>mash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resembles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attacks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>having</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>point</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23301</th>\n",
       "      <td>wpetqiitqyprypiy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23302</th>\n",
       "      <td>ywyeoiwtopypotpi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23303</th>\n",
       "      <td>tpoiouteiwppweiq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23304</th>\n",
       "      <td>pyiitiwiuyootpyq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23305</th>\n",
       "      <td>ieeyiewwpqtrwuwq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23306 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  words  mash\n",
       "0             resembles     0\n",
       "1               attacks     0\n",
       "2                 under     0\n",
       "3                having     0\n",
       "4                 point     0\n",
       "...                 ...   ...\n",
       "23301  wpetqiitqyprypiy     1\n",
       "23302  ywyeoiwtopypotpi     1\n",
       "23303  tpoiouteiwppweiq     1\n",
       "23304  pyiitiwiuyootpyq     1\n",
       "23305  ieeyiewwpqtrwuwq     1\n",
       "\n",
       "[23306 rows x 2 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X0, X1], axis=0).rename(columns={'0':'words'}, inplace=False).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23306x153986 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 569679 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract N-grams\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(2, 3), analyzer='char')\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 4), analyzer='char', stop_words=None)\n",
    "ngram_features = vectorizer.fit_transform(df['words'])\n",
    "# ngram_features = vectorizer.fit_transform(df['words']).toarray()\n",
    "ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>mash</th>\n",
       "      <th>vowel rt</th>\n",
       "      <th>consonant rt</th>\n",
       "      <th>ttr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resembles</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attacks</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>having</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>point</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23301</th>\n",
       "      <td>wpetqiitqyprypiy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23302</th>\n",
       "      <td>ywyeoiwtopypotpi</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23303</th>\n",
       "      <td>tpoiouteiwppweiq</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23304</th>\n",
       "      <td>pyiitiwiuyootpyq</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23305</th>\n",
       "      <td>ieeyiewwpqtrwuwq</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23306 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  words  mash  vowel rt  consonant rt       ttr\n",
       "0             resembles     0  0.333333      0.666667  0.666667\n",
       "1               attacks     0  0.285714      0.714286  0.714286\n",
       "2                 under     0  0.400000      0.600000  1.000000\n",
       "3                having     0  0.333333      0.666667  1.000000\n",
       "4                 point     0  0.400000      0.600000  1.000000\n",
       "...                 ...   ...       ...           ...       ...\n",
       "23301  wpetqiitqyprypiy     1  0.250000      0.750000  0.500000\n",
       "23302  ywyeoiwtopypotpi     1  0.375000      0.625000  0.437500\n",
       "23303  tpoiouteiwppweiq     1  0.500000      0.500000  0.500000\n",
       "23304  pyiitiwiuyootpyq     1  0.437500      0.562500  0.500000\n",
       "23305  ieeyiewwpqtrwuwq     1  0.375000      0.625000  0.562500\n",
       "\n",
       "[23306 rows x 5 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Análise de tamanho e razão de vogais e consoantes e de TTR\n",
    "\n",
    "aux = df.copy()\n",
    "aux[\"vowel rt\"] = aux[\"words\"].apply(lambda x : type_ratio(str(x), 'v'))\n",
    "aux[\"consonant rt\"] = aux[\"vowel rt\"].apply(lambda x : 1-x)\n",
    "aux[\"ttr\"] = aux[\"words\"].apply(ttr)\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_feature = csr_matrix(np.array(aux[\"vowel rt\"]).reshape(-1,1))\n",
    "consonant_feature = csr_matrix(np.array(aux[\"consonant rt\"]).reshape(-1,1))\n",
    "ttr_feature = csr_matrix(np.array(aux[\"ttr\"]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel_feature.shape: (30672, 1)\n",
      "consonant_feature.shape: (30672, 1)\n",
      "ttr_feature.shape: (30672, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"vowel_feature.shape: {vowel_feature.shape}\\nconsonant_feature.shape: {consonant_feature.shape}\\nttr_feature.shape: {ttr_feature.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23306, 3)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_features = hstack((vowel_feature, consonant_feature, ttr_feature))\n",
    "lexical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23306x153989 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 636097 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = hstack((lexical_features, ngram_features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30672x155183 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 716014 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the features (optional)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "features = scaler.fit_transform(np.abs(features))\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, df['mash'], test_size=0.4, random_state=777)\n",
    "\n",
    "# Train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = clf.score(features_test, labels_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9902391933926847\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, df['mash'], test_size=0.4, random_state=777)\n",
    "\n",
    "# Train the classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = clf.score(features_test, labels_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr(\"batatetitotu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]:pneumonoultramicroscopicsilicovolcanoconiosis:[[0.55 0.45]]\n"
     ]
    }
   ],
   "source": [
    "entrada = input(\"\")\n",
    "# Extract N-gram features for the new string\n",
    "input_ngram_features = vectorizer.transform([entrada])\n",
    "\n",
    "# Extract lexical features for the new string\n",
    "input_len_feature = csr_matrix(np.array(len(entrada)).reshape(-1,1))\n",
    "input_vowel_feature = csr_matrix(np.array(type_ratio(entrada, 'v')).reshape(-1,1))\n",
    "input_consonant_feature = csr_matrix(np.array(type_ratio(entrada, 'c')).reshape(-1,1))\n",
    "input_ttr_feature = csr_matrix(np.array(ttr(entrada)).reshape(-1,1))\n",
    "\n",
    "# Combine the N-gram and lexical features into a single feature matrix\n",
    "input_lexical_features = hstack((input_vowel_feature, input_consonant_feature, input_ttr_feature))\n",
    "input_features = hstack((input_lexical_features, input_ngram_features))\n",
    "\n",
    "# Make the prediction using the trained model\n",
    "prediction = clf.predict(input_features)\n",
    "predprob = clf.predict_proba(input_features)\n",
    "# Print the prediction\n",
    "print(f\"{prediction}:{entrada}:{predprob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]:yhtecwtatnelurf \n",
      "[1]:xzdagohdnioliou \n",
      "[1]:cictutbuvjnartoltitf\n",
      "[1]:ptulldegnjkruormytrq\n",
      "[1]:lnaebzbanatidiviejiu\n",
      "[1]:yatiacodlwalthrpzaao\n",
      "[1]:pruteebci\n",
      "[1]:zaembaedzc\n",
      "[1]:ihnccitws\n",
      "[1]:rondlrpe\n",
      "[1]:loeniaerkhyh\n",
      "[1]:ipippipoiopiopiopiop\n",
      "[1]:ipoiopiopipoipoiopiopiopio\n",
      "[1]:poipoiopopipioppi\n",
      "[1]:opoiopipoiopipoiop\n",
      "[1]:iopoioiopipoipoipo\n",
      "[1]:iouiuioiuouiuiouoioiu\n",
      "[1]:iouiouiouiouoiuioui\n",
      "[1]:ouiouiouiouiuyiiu\n",
      "[1]:rtyytrrytrytytrytryt\n",
      "[1]:trtrtrtrterererererererer\n",
      "[1]:ewewewewewewrerer\n",
      "[1]:ererereretrtetrtrtrytyt\n",
      "[1]:tyuituyituyuitoippoipoi\n",
      "[1]:zqmapmplmlpmlpmplpmlpmlpmlpmlpmlpmllpmlpmlpmlpmlpmlmlpmlplmpl\n",
      "[0]:c7pprmeeduss\n",
      "[1]:weustt9nneas\n",
      "[1]:tbassuahpfep\n",
      "[0]:kiraezy\n",
      "[1]:itheair\n",
      "[1]:nepsawl\n",
      "[1]:hwrcosb\n",
      "[0]:finiefj\n",
      "[1]:nmimcom\n",
      "[0]:hriphao\n",
      "[1]:xourgec\n",
      "[0]:tacimu4\n",
      "[1]:ouiulct\n",
      "[0]:nuppuno\n",
      "[0]:a8nutss\n",
      "[0]:knfelnpesroopcc\n",
      "[1]:vpieaporitfuccy\n",
      "[1]:jiaxddeuhnturarefj\n",
      "[1]:eu1cvgirtronn\n"
     ]
    }
   ],
   "source": [
    "entradas = [\"yhtecwtatnelurf \", \"xzdagohdnioliou \", \"cictutbuvjnartoltitf\", \"ptulldegnjkruormytrq\",\n",
    "         \"lnaebzbanatidiviejiu\", \"yatiacodlwalthrpzaao\", \"pruteebci\", \"zaembaedzc\", \"ihnccitws\",\n",
    "         \"rondlrpe\", \"loeniaerkhyh\", \"ipippipoiopiopiopiop\", \"ipoiopiopipoipoiopiopiopio\", \"poipoiopopipioppi\",\n",
    "         \"opoiopipoiopipoiop\", \"iopoioiopipoipoipo\", \"iouiuioiuouiuiouoioiu\", \"iouiouiouiouoiuioui\", \"ouiouiouiouiuyiiu\",\n",
    "         \"rtyytrrytrytytrytryt\", \"trtrtrtrterererererererer\", \"ewewewewewewrerer\", \"ererereretrtetrtrtrytyt\", \"tyuituyituyuitoippoipoi\",\n",
    "         \"zqmapmplmlpmlpmplpmlpmlpmlpmlpmlpmllpmlpmlpmlpmlpmlmlpmlplmpl\", \"c7pprmeeduss\", \"weustt9nneas\", \"tbassuahpfep\",\n",
    "         \"kiraezy\", \"itheair\", \"nepsawl\", \"hwrcosb\", \"finiefj\", \"nmimcom\", \"hriphao\", \"xourgec\", \"tacimu4\", \"ouiulct\",\n",
    "         \"nuppuno\", \"a8nutss\", \"knfelnpesroopcc\", \"vpieaporitfuccy\", \"jiaxddeuhnturarefj\", \"eu1cvgirtronn\"]\n",
    "for entrada in entradas:\n",
    "    # Extract N-gram features for the new string\n",
    "    input_ngram_features = vectorizer.transform([entrada])\n",
    "\n",
    "    # Extract lexical features for the new string\n",
    "    input_len_feature = csr_matrix(np.array(len(entrada)).reshape(-1,1))\n",
    "    input_vowel_feature = csr_matrix(np.array(type_ratio(entrada, 'v')).reshape(-1,1))\n",
    "    input_consonant_feature = csr_matrix(np.array(type_ratio(entrada, 'c')).reshape(-1,1))\n",
    "    input_ttr_feature = csr_matrix(np.array(ttr(entrada)).reshape(-1,1))\n",
    "\n",
    "    # Combine the N-gram and lexical features into a single feature matrix\n",
    "    input_lexical_features = hstack((input_vowel_feature, input_consonant_feature, input_ttr_feature))\n",
    "    input_features = hstack((input_lexical_features, input_ngram_features))\n",
    "\n",
    "    # Make the prediction using the trained model\n",
    "    prediction = clf.predict(input_features)\n",
    "\n",
    "    # Print the prediction\n",
    "    print(f\"{prediction}:{entrada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"..\\\\data\\\\raw\\\\words.csv\", \"r\", encoding=\"utf-8\") as file1:\n",
    "    words = pd.DataFrame(pd.read_csv(file1, keep_default_na=False))\n",
    "strwords = words.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asclepiadaceae\n",
      "bouzouki\n",
      "chrysops\n",
      "dybbuks\n",
      "diiambus\n",
      "fylgja\n",
      "hajilij\n",
      "hylaeosaurus\n",
      "hrzn\n",
      "yokohama\n",
      "iteaceae\n",
      "jussieuan\n",
      "kokowai\n",
      "kowagmiut\n",
      "naumachiae\n",
      "nectrioidaceae\n",
      "phlegms\n",
      "pleuropterygii\n",
      "raiae\n",
      "scypphi\n",
      "scribbly\n",
      "siliquose\n",
      "syndactyly\n",
      "squooshed\n",
      "tymbals\n",
      "tsktsk\n",
      "zoaea\n",
      "zoogloeal\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for entrada in strwords:\n",
    "    i += 1\n",
    "    if (i % 100 != 0):\n",
    "        continue\n",
    "    # Extract N-gram features for the new string\n",
    "    input_ngram_features = vectorizer.transform([entrada])\n",
    "\n",
    "    # Extract lexical features for the new string\n",
    "    input_vowel_feature = csr_matrix(np.array(type_ratio(entrada, 'v')).reshape(-1,1))\n",
    "    input_consonant_feature = csr_matrix(np.array(type_ratio(entrada, 'c')).reshape(-1,1))\n",
    "    input_ttr_feature = csr_matrix(np.array(ttr(entrada)).reshape(-1,1))\n",
    "\n",
    "    # Combine the N-gram and lexical features into a single feature matrix\n",
    "    input_lexical_features = hstack((input_vowel_feature, input_consonant_feature, input_ttr_feature))\n",
    "    input_features = hstack((input_lexical_features, input_ngram_features))\n",
    "\n",
    "    # Make the prediction using the trained model\n",
    "    prediction = clf.predict(input_features)\n",
    "\n",
    "    # Print the prediction\n",
    "    if prediction:\n",
    "        print(f\"{entrada}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"..\\\\data\\\\raw\\\\falsospositivos.txt\", \"r\", encoding=\"utf-8\") as file1:\n",
    "    fpos = [line.rstrip('\\n') for line in file1]\n",
    "with open (\"..\\\\data\\\\raw\\\\erros_ml_words.txt\", \"r\", encoding=\"utf-8\") as file2:\n",
    "    erros = [line.rstrip('\\n') for line in file2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for word in erros:\n",
    "    try:\n",
    "        if fpos.index(word) != ValueError:\n",
    "            print(f\"{word}\")\n",
    "    except:\n",
    "        continue;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38b444d0255ad8ae1b6474cf1705948d47c9a753211d06096071fba803b18e24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
